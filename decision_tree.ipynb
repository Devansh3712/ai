{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "A supervised learning algorithm used for both classification and regression tasks. It works by recursively partitioning the input space into regions and assigning labels to those regions based on the input features.\n",
    "\n",
    "### Information Gain\n",
    "One of the criteria used to decide which feature to split on at each node of the decision tree. It measures the reduction in entropy that results from splitting the data based on a particular feature. Entropy is a measure of randomness or uncertainity in a dataset.\n",
    "\n",
    "$H(S) = -\\sum_{i=1}^{c} p_i \\log_2(p_i)$\n",
    "\n",
    "$IG(S, A) = H(S) - \\sum_{v=1}^{m} \\left( \\frac{|S_v|}{|S|} \\cdot H(S_v) \\right)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Node:\n",
    "    def __init__(\n",
    "        self,\n",
    "        feature=None,\n",
    "        threshold=None,\n",
    "        left=None,\n",
    "        right=None,\n",
    "        *,\n",
    "        value=None,\n",
    "    ) -> None:\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value\n",
    "\n",
    "    @property\n",
    "    def is_leaf(self):\n",
    "        return self.value is not None\n",
    "\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(\n",
    "        self,\n",
    "        min_samples_split: int = 2,\n",
    "        max_depth: int = 100,\n",
    "        features=None\n",
    "    ) -> None:\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.features = features\n",
    "        self.root = None\n",
    "\n",
    "    def _entropy(self, y):\n",
    "        count = np.bincount(y)\n",
    "        p = count / len(y)\n",
    "        return -np.sum([i * np.log(i) for i in p if i > 0])\n",
    "\n",
    "    def _split(self, X_column, split_threshold):\n",
    "        left = np.argwhere(X_column <= split_threshold).flatten()\n",
    "        right = np.argwhere(X_column > split_threshold).flatten()\n",
    "        return left, right\n",
    "\n",
    "    def _information_gain(self, y, X_column, threshold):\n",
    "        parent_entropy = self._entropy(y)\n",
    "        left, right = self._split(X_column, threshold)\n",
    "        if len(left) == 0 or len(right) == 0:\n",
    "            return 0\n",
    "\n",
    "        length = len(y)\n",
    "        left_length, right_length = len(left), len(right)\n",
    "        left_entropy, right_entropy = self._entropy(y[left]), self._entropy(y[right])\n",
    "        child_entropy = (left_length / length) * left_entropy \\\n",
    "            + (right_length / length) * right_entropy\n",
    "\n",
    "        return parent_entropy - child_entropy\n",
    "\n",
    "\n",
    "    def _best_split(self, X, y, rfeatures):\n",
    "        best_gain = -1\n",
    "        split_feature, split_threshold = None, None\n",
    "\n",
    "        for feature in rfeatures:\n",
    "            X_column = X[:, feature]\n",
    "            thresholds = np.unique(X_column)\n",
    "\n",
    "            for threshold in thresholds:\n",
    "                gain = self._information_gain(y, X_column, threshold)\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    split_feature = feature\n",
    "                    split_threshold = threshold\n",
    "\n",
    "        return split_feature, split_threshold\n",
    "\n",
    "    def _grow_tree(self, X, y, depth=0):\n",
    "        n_samples, n_features = X.shape\n",
    "        n_labels = len(np.unique(y))\n",
    "\n",
    "        if depth >= self.max_depth or n_labels == 1 or n_samples < self.min_samples_split:\n",
    "            counter = Counter(y)\n",
    "            leaf_value = counter.most_common(1)[0][0]\n",
    "            return Node(value=leaf_value)\n",
    "\n",
    "        rfeatures = np.random.choice(n_features, self.features, replace=False)\n",
    "        best_feature, best_threshold = self._best_split(X, y, rfeatures)\n",
    "\n",
    "        left_idx, right_idx = self._split(X[:, best_feature], best_threshold)\n",
    "        left = self._grow_tree(X[left_idx,:], y[left_idx], depth+1)\n",
    "        right = self._grow_tree(X[right_idx,:], y[right_idx], depth+1)\n",
    "        return Node(best_feature, best_threshold, left, right)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.features = X.shape[1] if not self.features else min(X.shape[1], self.features)\n",
    "        self.root = self._grow_tree(X, y)\n",
    "\n",
    "    def _traverse_tree(self, x, node: Node):\n",
    "        if node.is_leaf:\n",
    "            return node.value\n",
    "\n",
    "        if x[node.feature] <= node.threshold:\n",
    "            return self._traverse_tree(x, node.left)\n",
    "        return self._traverse_tree(x, node.right)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._traverse_tree(x, self.root) for x in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9590643274853801"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = datasets.load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=10)\n",
    "\n",
    "classifier = DecisionTree()\n",
    "classifier.fit(X_train, y_train)\n",
    "predictions = classifier.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
